{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Foundations of Neural Networks\n",
    "Lab Author: Calvin Josenhans and Gautam Hari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About\n",
    "The aim of this lab is to provide you with a better understanding of the mechanisms at the heart of machine learning and artificial intelligence, Neural Networks.\n",
    "\n",
    "# Neural Networks? How is this Machine Learning?\n",
    "\n",
    "<img src=\".\\images\\Neural-Networks-Position.png\" alt=\"Where does Neural Networks lie in the field of AI?\" width=\"500\"/>\n",
    "\n",
    "It is important to note that the names you hear thrown around such as Artifical intelligence, Machine Learning and Deep Learning are all interconected with each other. As seen the the image, Artifical Intelligence is the broad term for a field of computer science that works with the intelligence or software(wikipedia).Machine Learning is a subfeild of Artifical intelligence that relies on \"learning from past data\". Deep Learning is a subsection of Machine Learning that uses Neural Networks as a backbone to function.  \n",
    "\n",
    "# Real World Usages of Neural Networks\n",
    "\n",
    "Neural Networks are all around us, impacting things from the YouTube videos you watch to the mail you get delivered. A classic example of a Neural Network in use is the United States Postal Service. Think about it: every day, the USPS delivers 420 million pieces of mail, that is a lot of addresses they need to ship to! They need a system that is able to process and sort addresses that are either handwritten or printed at an incredibly high rate. But the Postal Service has a secret weapon: Neural Networks! Using the process of Optical Character Recognition (OCR), the postal service can rapidly read information off of mail and utilize it in sending the parcel to its final destination."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Okay But, How Do Neural Networks Work?\n",
    "\n",
    "Well, to talk about this, let's take an example. Imagine you worked for the United States Postal Service, and you were given the task of sorting the mail based on Zip Code. Assuming we know where the zip code was located on every different piece of mail, our challenge is to read it!\n",
    "\n",
    "<img src=\".\\images\\Neural_network_explain.png\" alt=\"A Depiction of an Artificial Neural Network\" width=\"500\"/> \n",
    "\n",
    "The image above is a visual representation of a Neural Network. There are three major parts that you need to worry about. The Input Layer, the Hidden Layer, and the Output Layer.\n",
    "\n",
    "In our example of the Post office, let's assume that the camera that takes the images of the numbers gets a 28X28 pixel image. So, there is a grand total of 784 pixels in the image. Translating that to our input layer means there are 784 total neurons in our input layer.\n",
    "\n",
    "The hidden layer then does a bunch of \"hidden\" operations on that data. In a second we'll zoom in on one of these hidden layer neurons to get a better sense of exactly what is going on.\n",
    "\n",
    "The ouput layer represents the output of the network. In this case, we ultimately want the model to recognize the image as a number from 0-9, meaning we will have a total of 10 neurons in the output layer, one for each possible digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Math Behind A Neural Network\n",
    "\n",
    "Math, you mean those made-up symbols can actually be useful? Sadly, yes, In fact, Neural Networks are really just Linear Algebra and Calculus under the hood, but I will not go into most of those equations today as they are out of the scope of our lab.\n",
    "\n",
    "We will just focus on some of the math behind The activation of neurons.\n",
    "\n",
    "# Activation?\n",
    "\n",
    "<img src=\".\\images\\neuron.png\" alt=\"A Single Neuron in a neural network\" width=\"500\">\n",
    "\n",
    "\n",
    "The image above zooms in onto a single neuron.\n",
    "\n",
    "The variables $x_1, ..., x_n$ represent other neurons, the lines are the connections between the neurons, and the variables $w_1, ..., w_n$ represent the weights of the neurons.\n",
    "\n",
    "Activation of a neuron is what determines the output based on the input of a neuron determined by the activation function $f$, which is equal to  $Ïƒ(w_1*x_1 + w_2*x_2)$. The function takes the weights and multiplies them by the neuron values. Then, we add up all the values inside and place them within a sigmoidal function, which squashes the input values between 0 and 1.\n",
    "\n",
    "<img src=\".\\images\\Sigmoid function.png\" alt=\"Graphical Representation of Sigmodial Function\" width=\"500\">\n",
    "\n",
    "\n",
    "Going back to our example of the Postal Service, we know that every pixel of the image has an RGB value of 0-255. In the case of Identifying Numbers, we are converting the image to grayscale and, from there, getting the grayscale value. How \"grayscale\" something is affects how much our neuron activates.\n",
    "\n",
    "# Weights\n",
    "\n",
    "What about the weights you mentioned earlier? Well, those are a bit more complicated.\n",
    "\n",
    "To put it simply, the weight is how much the Network values the activation of a Neuron. The weights are what the Neural Network messes with to \"Learn.\" We will not cover how the Nueral Network does this backpropagation in-depth as the math behind it can get messy, but for those interested, Neural Networks work by something known as \"Backpropagation.\" Backpropagation is what alters the weights in the model to make it more and more accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Own Neural Network\n",
    "Let's say that we want to create a simple neural network that can tell us what color a flower will be in a field.\n",
    "\n",
    "<img src=\".\\images\\Meadow-with-lots-of-yellow-flowers-scaled.jpg\" alt=\"A Depiction of an Artificial Neural Network\" width=\"500\"/> \n",
    "\n",
    "It turns out that we can solve this problem with the simplest possible neural network, consisting of a single neuron called a **perceptron**.\n",
    "\n",
    "## Getting Started with Code\n",
    "Just like our neuron, our perceptron will have the ability to accept inputs, multiply those inputs by its own set of weights, and then output a number between -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import random, sample\n",
    "\n",
    "class Perceptron:\n",
    "    def __init__(self, num_inputs):\n",
    "        # Giving the perceptron its learning constant\n",
    "        # This is a variable that controls how fast the perceptron learns\n",
    "        self.c = 0.2\n",
    "        self.weights = list()\n",
    "        for i in range(num_inputs):\n",
    "            self.weights.append(random() * 2 - 1)\n",
    "\n",
    "    # A very simple function that decices whether the perceptron outputs a signal or not\n",
    "    # Returns 1 if the number is positive, and -1 otherwise\n",
    "    def activate(self, n):\n",
    "        if n < 0: return -1\n",
    "        return 1\n",
    "\n",
    "    # Runs the inputs through the perceptron\n",
    "    def feedforward(self, inputs):\n",
    "        sum = 0\n",
    "        # Multiply every input by the corresponding weight\n",
    "        for i, input in enumerate(inputs):\n",
    "            sum += input * self.weights[i]\n",
    "\n",
    "        return self.activate(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Our Perceptron\n",
    "As our perceptron is, it can already make predictions about what color flowers we will see. Our perceptron will have 3 inputs, the x and y coordinates of the flower, and a bias term.\n",
    "\n",
    "The bias term may seem strange at first, but it begins to make sense if we think about what happens for the point (0, 0). No matter what the weights of the perceptron are, it will always output 0, which is not very useful. By adding the bias term we are able to account for this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting function that we'll use later\n",
    "# It draws a graph of the network's predictions, colored either purple or yellow, depending on the prediction.\n",
    "def plot_results(inputs, outputs):\n",
    "    xs = [x for (x, y, b) in inputs]\n",
    "    ys = [y for (x, y, b) in inputs]\n",
    "\n",
    "    plt.scatter(xs, ys, c=outputs, cmap='viridis')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a perceptron with 3 inputs, an x, y and bias.\n",
    "perceptron = Perceptron(3)\n",
    "\n",
    "# There is a flower at every coordinate point\n",
    "flower_locations = []\n",
    "for i in range(-25, 25):\n",
    "    for j in range(-25, 25):\n",
    "        flower_locations.append([i, j, 1])\n",
    "\n",
    "\n",
    "# Keeping track of the predictions that the perceptron makes\n",
    "flower_colors = []\n",
    "for loc in flower_locations:\n",
    "    prediction = perceptron.feedforward(loc)\n",
    "    flower_colors.append(prediction)\n",
    "\n",
    "plot_results(flower_locations, flower_colors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Graph\n",
    "Notice the linear boundary between the two colors of flowers. This is because our network only has 1 neuron (so technically it isn't a network at all!). Increasing the size of our network allows for handling more complex data as we'll see later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Right now, our perceptron is simply guessing at a distribution of flowers. The real power comes with the ability to train the perceptron based on just a few datapoints, to learn the pattern of data distribution.\n",
    "\n",
    "## A training algorithm\n",
    "1. Provide the perceptron with inputs where there is a known answer. \n",
    "2. Ask the perceptron to guess an answer for those inputs.\n",
    "3. Compute the error - i.e. how close to the correct answer was the perceptron.\n",
    "4. Adjust the weights based on the error.\n",
    "5. Repeat!\n",
    "\n",
    "When we provide enough trading data, this process allows us to fine-tune the perceptron's weights to predict as accurately as possible the locations of flowers.\n",
    "\n",
    "## Translating this algorithm into code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another method for the perceptron class\n",
    "def train(self: Perceptron, inputs, answer):\n",
    "    # Finding what the perceptron predicts\n",
    "    guess = self.feedforward(inputs)\n",
    "    # Getting how wrong we were (and in what direction)\n",
    "    error = guess - answer\n",
    "\n",
    "    # Changing the weights to be closer to the expected value\n",
    "    for i in range(len(self.weights)):\n",
    "        self.weights[i] += self.c * error * inputs[i]\n",
    "\n",
    "\n",
    "# Assigning the method to the class (Yay Python!)\n",
    "Perceptron.train = train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But First!\n",
    "Before we actually run the code to train the perceptron, let's see how our perceptron with just random weights does with predicting things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The \"true\" distribution of the flowers\n",
    "# This could be anything, but we're just choosing it as something to compare our model to.\n",
    "def f(x):\n",
    "    return 2*x + 1\n",
    "\n",
    "# Function that compares the predictions to the actual output\n",
    "def evaluate():\n",
    "    xs = []\n",
    "    ys = []\n",
    "    outputs = []\n",
    "    # Guessing the color of a bunch of random flowers\n",
    "    for i in range(100):\n",
    "        x = random() * 50 - 25\n",
    "        y = random() * 50 - 25\n",
    "\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "        outputs.append(perceptron.feedforward([x, y, 1]))\n",
    "\n",
    "\n",
    "    plt.scatter(xs, ys, c=outputs,cmap='viridis')\n",
    "\n",
    "    plt.plot([-25, 25], [f(-25), f(25)], color='green', marker='', linestyle='dotted')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty bad right? But now we'll train the perceptron on all of our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually Training\n",
    "We already generated some data for our flowers, so lets just choose a few random points out of those to be our training sets: `flower_locations` (inputs) and `flower_colors` (outputs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How much training data we want to use\n",
    "num_training_points = 1000\n",
    "\n",
    "# Select a random portion of the points we have.\n",
    "inputs = []\n",
    "outputs = []\n",
    "\n",
    "# Generating a number of points to train with\n",
    "for i in range(num_training_points):\n",
    "    x = random() * 50 - 25\n",
    "    y = random() * 50 - 25    \n",
    "\n",
    "    # Getting the correct output based on our function\n",
    "    out = 1 if f(x) > y else -1\n",
    "\n",
    "    inputs.append((x,y,1))\n",
    "    outputs.append(out)\n",
    "\n",
    "# Training our perceptron\n",
    "for i in range(len(inputs)):\n",
    "    perceptron.train(inputs[i], outputs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing how we did\n",
    "Let's compare the predictions of our perceptron to the line y=2x + 1 that represents the actual distribution we're aiming for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling the function to display our results\n",
    "evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much closer right?\n",
    "\n",
    "If you want, you can even run the code block again to generate some more data, and you should see the predictions get even closer to the actual line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "We looked at how neural networks work by seeking to model human neurons.\n",
    "\n",
    "We then created and trained our own perceptron to predict the color of flowers in a field.\n",
    "\n",
    "Although this model is extremely simple, by connecting perceptrons together it's possible to train neural networks to model and predict much more complex phenomena. Hopefully by walking through this example, you have a better sense of what is going on at the very core of one of the most important tools in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources\n",
    "- https://natureofcode.com/book/chapter-10-neural-networks/\n",
    "- https://en.wikipedia.org/wiki/Machine_learning#Model_assessments\n",
    "- https://en.wikipedia.org/wiki/Artificial_neural_network\n",
    "# Images\n",
    "- https://stats.stackexchange.com/questions/487249/       why-is-learning-slower-for-a-sigmoid-activation-function-in-a-neural-network\n",
    "- https://medium.com/@silvaan/what-is-the-difference-between-artificial-intelligence-machine-learning-and-deep-learning-71ec27ea5a2a\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
